{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zheyaogao/anaconda3/envs/esd_seg/lib/python3.10/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import \\\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mmcv.cnn import ConvModule\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "\n",
    "\n",
    "class Adapter(nn.Module):\n",
    "    def __init__(self, blk) -> None:\n",
    "        super(Adapter, self).__init__()\n",
    "        self.block = blk\n",
    "        dim = blk.attn.qkv.in_features\n",
    "        self.prompt_learn = nn.Sequential(\n",
    "            nn.Linear(dim, 32),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(32, dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        prompt = self.prompt_learn(x)\n",
    "        promped = x + prompt\n",
    "        net = self.block(promped)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MemoryAttentionModule(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # Self-attention for memory features\n",
    "        self.self_attention = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Cross-attention between current frame and memory\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Layer normalization and feed-forward network\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(4 * embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, current_features, memory_features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            current_features: Features of current frame [B, H*W, C]\n",
    "            memory_features: Features of memory frames [B, T*H*W, C]\n",
    "        Returns:\n",
    "            Enhanced current features with memory information\n",
    "        \"\"\"\n",
    "        # Self-attention on memory features\n",
    "        memory_out = self.self_attention(\n",
    "            memory_features,\n",
    "            memory_features,\n",
    "            memory_features\n",
    "        )[0]\n",
    "        memory_out = self.norm1(memory_features + memory_out)\n",
    "        \n",
    "        # Cross-attention between current features and memory\n",
    "        current_out = self.cross_attention(\n",
    "            current_features,\n",
    "            memory_out,\n",
    "            memory_out\n",
    "        )[0]\n",
    "        current_out = self.norm2(current_features + current_out)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        ffn_out = self.ffn(current_out)\n",
    "        output = self.norm3(current_out + ffn_out)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class VideoSegmentationModel(nn.Module):\n",
    "    def __init__(self, backbone, embed_dim=256, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.memory_module = MemoryAttentionModule(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "        \n",
    "        self.memory_buffer = None\n",
    "        self.buffer_size = 5  # Number of frames to keep in memory\n",
    "        \n",
    "    def update_memory(self, features):\n",
    "        \"\"\"Update memory buffer with new features\"\"\"\n",
    "        if self.memory_buffer is None:\n",
    "            self.memory_buffer = features.unsqueeze(1)\n",
    "        else:\n",
    "            self.memory_buffer = torch.cat([\n",
    "                self.memory_buffer,\n",
    "                features.unsqueeze(1)\n",
    "            ], dim=1)\n",
    "            \n",
    "            # Keep only recent frames\n",
    "            if self.memory_buffer.size(1) > self.buffer_size:\n",
    "                self.memory_buffer = self.memory_buffer[:, -self.buffer_size:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input frame [B, C, H, W]\n",
    "        \"\"\"\n",
    "        # Extract features using backbone\n",
    "        features = self.backbone(x)\n",
    "        B, C, H, W = features.shape\n",
    "        \n",
    "        # Reshape features to sequence format\n",
    "        features = features.flatten(2).transpose(1, 2)  # [B, H*W, C]\n",
    "        \n",
    "        # Update memory buffer\n",
    "        self.update_memory(features)\n",
    "        \n",
    "        # Flatten memory buffer for attention\n",
    "        memory_features = self.memory_buffer.view(\n",
    "            B, -1, C\n",
    "        )  # [B, T*H*W, C]\n",
    "        \n",
    "        # Apply memory attention\n",
    "        enhanced_features = self.memory_module(features, memory_features)\n",
    "        \n",
    "        # Reshape back to spatial format\n",
    "        output = enhanced_features.transpose(1, 2).view(B, C, H, W)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SAM2Adapt(nn.Module):\n",
    "    def __init__(self, checkpoint_path=None) -> None:\n",
    "        super(SAM2Adapt, self).__init__()    \n",
    "        checkpoint_path = \"../sam2/checkpoints/sam2.1_hiera_large.pt\"\n",
    "        model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "        if checkpoint_path:\n",
    "            model = build_sam2(model_cfg, checkpoint_path)\n",
    "        else:\n",
    "            model = build_sam2(model_cfg)\n",
    "        del model.sam_mask_decoder\n",
    "        del model.sam_prompt_encoder\n",
    "        del model.memory_encoder\n",
    "        del model.memory_attention\n",
    "        del model.mask_downsample\n",
    "        del model.obj_ptr_tpos_proj\n",
    "        del model.obj_ptr_proj\n",
    "        del model.image_encoder.neck\n",
    "\n",
    "        self.encoder = model.image_encoder.trunk\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        blocks = []\n",
    "        for block in self.encoder.blocks:\n",
    "            blocks.append(\n",
    "                Adapter(block)\n",
    "            )\n",
    "        self.encoder.blocks = nn.Sequential(\n",
    "            *blocks\n",
    "        )\n",
    "\n",
    "        # self.memory_attention = MemoryAttentionModule(embed_dim=)\n",
    "        \n",
    "\n",
    "\n",
    "    def get_memory(self,x):\n",
    "        T, B, C, H, W = x.shape\n",
    "        with torch.no_grad():\n",
    "            x = self.encoder(x.contiguous().view(-1,C,H,W))\n",
    "        \n",
    "        _, C, H, W = x[-1].shape \n",
    "        return x[-1].view(T, B, C, H, W)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_curr, x_memo = x[0], x[1:]\n",
    "        f_curr = self.encoder(x_curr)\n",
    "\n",
    "        return f_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zheyaogao/Experiments/ESD_seg/sam2/modeling/sam/transformer.py:23: UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n",
      "  OLD_GPU, USE_FLASH_ATTN, MATH_KERNEL_ON = get_sdpa_settings()\n"
     ]
    }
   ],
   "source": [
    "model = SAM2Adapt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=144, out_features=432, bias=True)\n",
       "        (proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=144, out_features=576, bias=True)\n",
       "          (1): Linear(in_features=576, out_features=144, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=144, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=144, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (1): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=144, out_features=432, bias=True)\n",
       "        (proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=144, out_features=576, bias=True)\n",
       "          (1): Linear(in_features=576, out_features=144, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=144, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=144, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (2): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "      (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        (qkv): Linear(in_features=144, out_features=864, bias=True)\n",
       "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "          (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "      (proj): Linear(in_features=144, out_features=288, bias=True)\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=144, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=144, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (3): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
       "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "          (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=288, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=288, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (4): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
       "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "          (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=288, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=288, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (5): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
       "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "          (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=288, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=288, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (6): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
       "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "          (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=288, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=288, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (7): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
       "        (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "          (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=288, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=288, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (8): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "      (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        (qkv): Linear(in_features=288, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "      (proj): Linear(in_features=288, out_features=576, bias=True)\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=288, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=288, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (9): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (10): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (11): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (12): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (13): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (14): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (15): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (16): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (17): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (18): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (19): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (20): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (21): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (22): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (23): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (24): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (25): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (26): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (27): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (28): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (29): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (30): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (31): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (32): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (33): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (34): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (35): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (36): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (37): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (38): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (39): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (40): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (41): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (42): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (43): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "        (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "          (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (44): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "      (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "        (qkv): Linear(in_features=576, out_features=3456, bias=True)\n",
       "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "      (proj): Linear(in_features=576, out_features=1152, bias=True)\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=576, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=576, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (45): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=1152, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=1152, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (46): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=1152, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=1152, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       "  (47): Adapter(\n",
       "    (block): MultiScaleBlock(\n",
       "      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiScaleAttention(\n",
       "        (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "          (1): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "        )\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (prompt_learn): Sequential(\n",
       "      (0): Linear(in_features=1152, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=1152, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer = list(model.encoder.children())[-1]\n",
    "last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1152/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256, 64, 64]) torch.Size([32, 256, 64, 64])\n",
      "torch.Size([32, 256, 32, 32]) torch.Size([32, 256, 32, 32])\n",
      "torch.Size([32, 256, 16, 16]) torch.Size([32, 256, 16, 16])\n",
      "torch.Size([32, 256, 8, 8]) torch.Size([32, 256, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model = SAM2Adapt().cuda()\n",
    "    x = torch.randn(8, 32, 3, 256, 256).cuda()\n",
    "    f, pos = model(x)\n",
    "    for x1, x2 in zip(f,pos):\n",
    "        print(x1.shape,x2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esd_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
